{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca76619a",
   "metadata": {},
   "source": [
    "## Basic Fundamental Operations using Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eceba492",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abef0f92",
   "metadata": {},
   "source": [
    "### 1. Creating Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3255985e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D Tensor: tf.Tensor([1 2 3 4 5], shape=(5,), dtype=int32)\n",
      "Shape: (5,)\n",
      "Rank: 1\n",
      "\n",
      "2D Tensor:\n",
      " tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]], shape=(2, 3), dtype=int32)\n",
      "Shape: (2, 3)\n",
      "Rank: 2\n",
      "\n",
      "3D Tensor:\n",
      " tf.Tensor(\n",
      "[[[1 2]\n",
      "  [3 4]]\n",
      "\n",
      " [[5 6]\n",
      "  [7 8]]], shape=(2, 2, 2), dtype=int32)\n",
      "Shape: (2, 2, 2)\n",
      "Rank: 3\n",
      "\n",
      "4D Tensor shape: (2, 3, 4, 5)\n",
      "Rank: 4\n",
      "\n",
      "Zeros:\n",
      " tf.Tensor(\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]], shape=(3, 3), dtype=float32)\n",
      "\n",
      "Ones:\n",
      " tf.Tensor(\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]], shape=(2, 4), dtype=float32)\n",
      "\n",
      "Random:\n",
      " tf.Tensor(\n",
      "[[ 0.86209244  0.7580136   0.942517  ]\n",
      " [ 0.36195517 -0.1641336  -0.66196865]\n",
      " [-0.16825125 -0.50829244  0.05707361]], shape=(3, 3), dtype=float32)\n",
      "\n",
      "Range: tf.Tensor([0 2 4 6 8], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Creating tensors of different dimensions\n",
    "# 1D Tensor (Vector)\n",
    "tensor_1d = tf.constant([1, 2, 3, 4, 5])\n",
    "print(\"1D Tensor:\", tensor_1d)\n",
    "print(\"Shape:\", tensor_1d.shape)\n",
    "print(\"Rank:\", tf.rank(tensor_1d).numpy())\n",
    "\n",
    "# 2D Tensor (Matrix)\n",
    "tensor_2d = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "print(\"\\n2D Tensor:\\n\", tensor_2d)\n",
    "print(\"Shape:\", tensor_2d.shape)\n",
    "print(\"Rank:\", tf.rank(tensor_2d).numpy())\n",
    "\n",
    "# 3D Tensor\n",
    "tensor_3d = tf.constant([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "print(\"\\n3D Tensor:\\n\", tensor_3d)\n",
    "print(\"Shape:\", tensor_3d.shape)\n",
    "print(\"Rank:\", tf.rank(tensor_3d).numpy())\n",
    "\n",
    "# 4D Tensor\n",
    "tensor_4d = tf.random.normal([2, 3, 4, 5])\n",
    "print(\"\\n4D Tensor shape:\", tensor_4d.shape)\n",
    "print(\"Rank:\", tf.rank(tensor_4d).numpy())\n",
    "\n",
    "# Special tensors\n",
    "zeros = tf.zeros([3, 3])\n",
    "ones = tf.ones([2, 4])\n",
    "random = tf.random.normal([3, 3])\n",
    "range_tensor = tf.range(0, 10, 2)\n",
    "\n",
    "print(\"\\nZeros:\\n\", zeros)\n",
    "print(\"\\nOnes:\\n\", ones)\n",
    "print(\"\\nRandom:\\n\", random)\n",
    "print(\"\\nRange:\", range_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6390ac",
   "metadata": {},
   "source": [
    "### 2. Tensor Rank Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ee38f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of 1D tensor: 1\n",
      "Rank of 2D tensor: 2\n",
      "Rank of 3D tensor: 3\n",
      "Rank of 4D tensor: 4\n",
      "\n",
      "Using ndim attribute:\n",
      "Rank of 1D tensor: 1\n",
      "Rank of 2D tensor: 2\n",
      "Rank of 3D tensor: 3\n",
      "Rank of 4D tensor: 4\n",
      "\n",
      "1D Tensor - Rank: 1 Shape: (5,) Size: 5\n",
      "2D Tensor - Rank: 2 Shape: (2, 3) Size: 6\n",
      "3D Tensor - Rank: 3 Shape: (2, 2, 2) Size: 8\n",
      "4D Tensor - Rank: 4 Shape: (2, 3, 4, 5) Size: 120\n"
     ]
    }
   ],
   "source": [
    "# Rank (number of dimensions) of tensors\n",
    "print(\"Rank of 1D tensor:\", tf.rank(tensor_1d).numpy())\n",
    "print(\"Rank of 2D tensor:\", tf.rank(tensor_2d).numpy())\n",
    "print(\"Rank of 3D tensor:\", tf.rank(tensor_3d).numpy())\n",
    "print(\"Rank of 4D tensor:\", tf.rank(tensor_4d).numpy())\n",
    "\n",
    "# Alternative: using ndim\n",
    "print(\"\\nUsing ndim attribute:\")\n",
    "print(\"Rank of 1D tensor:\", tensor_1d.ndim)\n",
    "print(\"Rank of 2D tensor:\", tensor_2d.ndim)\n",
    "print(\"Rank of 3D tensor:\", tensor_3d.ndim)\n",
    "print(\"Rank of 4D tensor:\", tensor_4d.ndim)\n",
    "\n",
    "# Getting detailed information\n",
    "print(\"\\n1D Tensor - Rank:\", tf.rank(tensor_1d).numpy(), \"Shape:\", tensor_1d.shape, \"Size:\", tf.size(tensor_1d).numpy())\n",
    "print(\"2D Tensor - Rank:\", tf.rank(tensor_2d).numpy(), \"Shape:\", tensor_2d.shape, \"Size:\", tf.size(tensor_2d).numpy())\n",
    "print(\"3D Tensor - Rank:\", tf.rank(tensor_3d).numpy(), \"Shape:\", tensor_3d.shape, \"Size:\", tf.size(tensor_3d).numpy())\n",
    "print(\"4D Tensor - Rank:\", tf.rank(tensor_4d).numpy(), \"Shape:\", tensor_4d.shape, \"Size:\", tf.size(tensor_4d).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27da4a47",
   "metadata": {},
   "source": [
    "### 3. Basic Arithmetic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "994190e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition: tf.Tensor([ 6.  8. 10. 12.], shape=(4,), dtype=float32)\n",
      "Using +: tf.Tensor([ 6.  8. 10. 12.], shape=(4,), dtype=float32)\n",
      "\n",
      "Subtraction: tf.Tensor([-4. -4. -4. -4.], shape=(4,), dtype=float32)\n",
      "Using -: tf.Tensor([-4. -4. -4. -4.], shape=(4,), dtype=float32)\n",
      "\n",
      "Element-wise multiplication: tf.Tensor([ 5. 12. 21. 32.], shape=(4,), dtype=float32)\n",
      "Using *: tf.Tensor([ 5. 12. 21. 32.], shape=(4,), dtype=float32)\n",
      "\n",
      "Division: tf.Tensor([0.2        0.33333334 0.42857143 0.5       ], shape=(4,), dtype=float32)\n",
      "Using /: tf.Tensor([0.2        0.33333334 0.42857143 0.5       ], shape=(4,), dtype=float32)\n",
      "\n",
      "Power (a^2): tf.Tensor([ 1.  4.  9. 16.], shape=(4,), dtype=float32)\n",
      "Using **: tf.Tensor([ 1.  4.  9. 16.], shape=(4,), dtype=float32)\n",
      "\n",
      "Matrix multiplication:\n",
      "tf.Tensor(\n",
      "[[19. 22.]\n",
      " [43. 50.]], shape=(2, 2), dtype=float32)\n",
      "Using @ operator:\n",
      "tf.Tensor(\n",
      "[[19. 22.]\n",
      " [43. 50.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Create sample tensors\n",
    "a = tf.constant([1.0, 2.0, 3.0, 4.0])\n",
    "b = tf.constant([5.0, 6.0, 7.0, 8.0])\n",
    "\n",
    "# Addition\n",
    "print(\"Addition:\", tf.add(a, b))\n",
    "print(\"Using +:\", a + b)\n",
    "\n",
    "# Subtraction\n",
    "print(\"\\nSubtraction:\", tf.subtract(a, b))\n",
    "print(\"Using -:\", a - b)\n",
    "\n",
    "# Multiplication (element-wise)\n",
    "print(\"\\nElement-wise multiplication:\", tf.multiply(a, b))\n",
    "print(\"Using *:\", a * b)\n",
    "\n",
    "# Division\n",
    "print(\"\\nDivision:\", tf.divide(a, b))\n",
    "print(\"Using /:\", a / b)\n",
    "\n",
    "# Power\n",
    "print(\"\\nPower (a^2):\", tf.pow(a, 2))\n",
    "print(\"Using **:\", a ** 2)\n",
    "\n",
    "# Matrix multiplication for 2D tensors\n",
    "matrix_a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "matrix_b = tf.constant([[5.0, 6.0], [7.0, 8.0]])\n",
    "print(\"\\nMatrix multiplication:\")\n",
    "print(tf.matmul(matrix_a, matrix_b))\n",
    "print(\"Using @ operator:\")\n",
    "print(matrix_a @ matrix_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b17acb",
   "metadata": {},
   "source": [
    "### 4. Diff Operations on 1D Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5943719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 1D tensor: tf.Tensor([ 1.  3.  6. 10. 15.], shape=(5,), dtype=float32)\n",
      "Shape: (5,)\n",
      "Rank: 1\n",
      "\n",
      "1st order diff: tf.Tensor([2. 3. 4. 5.], shape=(4,), dtype=float32)\n",
      "Shape: (4,)\n",
      "\n",
      "2nd order diff: tf.Tensor([1. 1. 1.], shape=(3,), dtype=float32)\n",
      "Shape: (3,)\n",
      "\n",
      "\n",
      "Another example:\n",
      "Original: tf.Tensor([ 1.  4.  9. 16. 25.], shape=(5,), dtype=float32)\n",
      "1st diff: tf.Tensor([3. 5. 7. 9.], shape=(4,), dtype=float32)\n",
      "Interpretation: differences are [3, 5, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "# 1D Tensor Diff - calculates differences between adjacent elements\n",
    "tensor_1d_diff = tf.constant([1.0, 3.0, 6.0, 10.0, 15.0])\n",
    "print(\"Original 1D tensor:\", tensor_1d_diff)\n",
    "print(\"Shape:\", tensor_1d_diff.shape)\n",
    "print(\"Rank:\", tf.rank(tensor_1d_diff).numpy())\n",
    "\n",
    "# First order difference\n",
    "# TensorFlow doesn't have built-in diff, so we use slicing\n",
    "diff_1 = tensor_1d_diff[1:] - tensor_1d_diff[:-1]\n",
    "print(\"\\n1st order diff:\", diff_1)\n",
    "print(\"Shape:\", diff_1.shape)\n",
    "\n",
    "# Second order difference\n",
    "diff_2 = diff_1[1:] - diff_1[:-1]\n",
    "print(\"\\n2nd order diff:\", diff_2)\n",
    "print(\"Shape:\", diff_2.shape)\n",
    "\n",
    "# Different example\n",
    "x = tf.constant([1.0, 4.0, 9.0, 16.0, 25.0])\n",
    "print(\"\\n\\nAnother example:\")\n",
    "print(\"Original:\", x)\n",
    "diff_x = x[1:] - x[:-1]\n",
    "print(\"1st diff:\", diff_x)\n",
    "print(\"Interpretation: differences are [3, 5, 7, 9]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115402ca",
   "metadata": {},
   "source": [
    "### 5. Diff Operations on 2D Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "553369f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 2D tensor:\n",
      "tf.Tensor(\n",
      "[[ 1.  3.  6. 10.]\n",
      " [ 2.  5.  9. 14.]\n",
      " [ 3.  7. 12. 18.]], shape=(3, 4), dtype=float32)\n",
      "Shape: (3, 4)\n",
      "Rank: 2\n",
      "\n",
      "Diff along dimension 0 (row-wise):\n",
      "tf.Tensor(\n",
      "[[1. 2. 3. 4.]\n",
      " [1. 2. 3. 4.]], shape=(2, 4), dtype=float32)\n",
      "Shape: (2, 4)\n",
      "\n",
      "Diff along dimension 1 (column-wise):\n",
      "tf.Tensor(\n",
      "[[2. 3. 4.]\n",
      " [3. 4. 5.]\n",
      " [4. 5. 6.]], shape=(3, 3), dtype=float32)\n",
      "Shape: (3, 3)\n",
      "\n",
      "2nd order diff along dimension 1:\n",
      "tf.Tensor(\n",
      "[[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]], shape=(3, 2), dtype=float32)\n",
      "Shape: (3, 2)\n"
     ]
    }
   ],
   "source": [
    "# 2D Tensor Diff\n",
    "tensor_2d_diff = tf.constant([[1.0, 3.0, 6.0, 10.0],\n",
    "                               [2.0, 5.0, 9.0, 14.0],\n",
    "                               [3.0, 7.0, 12.0, 18.0]])\n",
    "print(\"Original 2D tensor:\")\n",
    "print(tensor_2d_diff)\n",
    "print(\"Shape:\", tensor_2d_diff.shape)\n",
    "print(\"Rank:\", tf.rank(tensor_2d_diff).numpy())\n",
    "\n",
    "# Diff along dimension 0 (rows)\n",
    "diff_dim0 = tensor_2d_diff[1:, :] - tensor_2d_diff[:-1, :]\n",
    "print(\"\\nDiff along dimension 0 (row-wise):\")\n",
    "print(diff_dim0)\n",
    "print(\"Shape:\", diff_dim0.shape)\n",
    "\n",
    "# Diff along dimension 1 (columns)\n",
    "diff_dim1 = tensor_2d_diff[:, 1:] - tensor_2d_diff[:, :-1]\n",
    "print(\"\\nDiff along dimension 1 (column-wise):\")\n",
    "print(diff_dim1)\n",
    "print(\"Shape:\", diff_dim1.shape)\n",
    "\n",
    "# Second order diff along dimension 1\n",
    "first_diff = tensor_2d_diff[:, 1:] - tensor_2d_diff[:, :-1]\n",
    "diff_2nd = first_diff[:, 1:] - first_diff[:, :-1]\n",
    "print(\"\\n2nd order diff along dimension 1:\")\n",
    "print(diff_2nd)\n",
    "print(\"Shape:\", diff_2nd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e3fb11",
   "metadata": {},
   "source": [
    "### 6. Diff Operations on 3D Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8b50a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 3D tensor:\n",
      "tf.Tensor(\n",
      "[[[ 0.  1.  2.  3.]\n",
      "  [ 4.  5.  6.  7.]\n",
      "  [ 8.  9. 10. 11.]]\n",
      "\n",
      " [[12. 13. 14. 15.]\n",
      "  [16. 17. 18. 19.]\n",
      "  [20. 21. 22. 23.]]], shape=(2, 3, 4), dtype=float32)\n",
      "Shape: (2, 3, 4)\n",
      "Rank: 3\n",
      "\n",
      "Diff along dimension 0:\n",
      "tf.Tensor(\n",
      "[[[12. 12. 12. 12.]\n",
      "  [12. 12. 12. 12.]\n",
      "  [12. 12. 12. 12.]]], shape=(1, 3, 4), dtype=float32)\n",
      "Shape: (1, 3, 4)\n",
      "\n",
      "Diff along dimension 1:\n",
      "tf.Tensor(\n",
      "[[[4. 4. 4. 4.]\n",
      "  [4. 4. 4. 4.]]\n",
      "\n",
      " [[4. 4. 4. 4.]\n",
      "  [4. 4. 4. 4.]]], shape=(2, 2, 4), dtype=float32)\n",
      "Shape: (2, 2, 4)\n",
      "\n",
      "Diff along dimension 2:\n",
      "tf.Tensor(\n",
      "[[[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]], shape=(2, 3, 3), dtype=float32)\n",
      "Shape: (2, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "# 3D Tensor Diff\n",
    "tensor_3d_diff = tf.reshape(tf.range(24, dtype=tf.float32), [2, 3, 4])\n",
    "print(\"Original 3D tensor:\")\n",
    "print(tensor_3d_diff)\n",
    "print(\"Shape:\", tensor_3d_diff.shape)\n",
    "print(\"Rank:\", tf.rank(tensor_3d_diff).numpy())\n",
    "\n",
    "# Diff along dimension 0\n",
    "diff_3d_dim0 = tensor_3d_diff[1:, :, :] - tensor_3d_diff[:-1, :, :]\n",
    "print(\"\\nDiff along dimension 0:\")\n",
    "print(diff_3d_dim0)\n",
    "print(\"Shape:\", diff_3d_dim0.shape)\n",
    "\n",
    "# Diff along dimension 1\n",
    "diff_3d_dim1 = tensor_3d_diff[:, 1:, :] - tensor_3d_diff[:, :-1, :]\n",
    "print(\"\\nDiff along dimension 1:\")\n",
    "print(diff_3d_dim1)\n",
    "print(\"Shape:\", diff_3d_dim1.shape)\n",
    "\n",
    "# Diff along dimension 2\n",
    "diff_3d_dim2 = tensor_3d_diff[:, :, 1:] - tensor_3d_diff[:, :, :-1]\n",
    "print(\"\\nDiff along dimension 2:\")\n",
    "print(diff_3d_dim2)\n",
    "print(\"Shape:\", diff_3d_dim2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e31e94",
   "metadata": {},
   "source": [
    "### 7. Diff Operations on 4D Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7335062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 4D tensor shape: (2, 3, 4, 5)\n",
      "Rank: 4\n",
      "\n",
      "First slice of 4D tensor:\n",
      "tf.Tensor(\n",
      "[[ 0.  1.  2.  3.  4.]\n",
      " [ 5.  6.  7.  8.  9.]\n",
      " [10. 11. 12. 13. 14.]\n",
      " [15. 16. 17. 18. 19.]], shape=(4, 5), dtype=float32)\n",
      "\n",
      "Diff along dimension 0 (batch): (1, 3, 4, 5)\n",
      "Diff along dimension 1 (channels): (2, 2, 4, 5)\n",
      "Diff along dimension 2 (height): (2, 3, 3, 5)\n",
      "Diff along dimension 3 (width): (2, 3, 4, 4)\n",
      "\n",
      "Diff along last dimension (width):\n",
      "First slice result:\n",
      "tf.Tensor(\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]], shape=(4, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 4D Tensor Diff (common in deep learning: batch_size, channels, height, width)\n",
    "tensor_4d_diff = tf.reshape(tf.range(120, dtype=tf.float32), [2, 3, 4, 5])\n",
    "print(\"Original 4D tensor shape:\", tensor_4d_diff.shape)\n",
    "print(\"Rank:\", tf.rank(tensor_4d_diff).numpy())\n",
    "print(\"\\nFirst slice of 4D tensor:\")\n",
    "print(tensor_4d_diff[0, 0, :, :])\n",
    "\n",
    "# Diff along different dimensions\n",
    "diff_4d_dim0 = tensor_4d_diff[1:, :, :, :] - tensor_4d_diff[:-1, :, :, :]\n",
    "diff_4d_dim1 = tensor_4d_diff[:, 1:, :, :] - tensor_4d_diff[:, :-1, :, :]\n",
    "diff_4d_dim2 = tensor_4d_diff[:, :, 1:, :] - tensor_4d_diff[:, :, :-1, :]\n",
    "diff_4d_dim3 = tensor_4d_diff[:, :, :, 1:] - tensor_4d_diff[:, :, :, :-1]\n",
    "\n",
    "print(\"\\nDiff along dimension 0 (batch):\", diff_4d_dim0.shape)\n",
    "print(\"Diff along dimension 1 (channels):\", diff_4d_dim1.shape)\n",
    "print(\"Diff along dimension 2 (height):\", diff_4d_dim2.shape)\n",
    "print(\"Diff along dimension 3 (width):\", diff_4d_dim3.shape)\n",
    "\n",
    "# Example: diff along the last dimension\n",
    "print(\"\\nDiff along last dimension (width):\")\n",
    "print(\"First slice result:\")\n",
    "print(diff_4d_dim3[0, 0, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d956ed6",
   "metadata": {},
   "source": [
    "### 8. Reshaping Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1a6741a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 1D tensor: tf.Tensor([ 0  1  2  3  4  5  6  7  8  9 10 11], shape=(12,), dtype=int32)\n",
      "Shape: (12,)\n",
      "\n",
      "Reshaped to 3x4:\n",
      "tf.Tensor(\n",
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]], shape=(3, 4), dtype=int32)\n",
      "\n",
      "Reshaped to 2x2x3:\n",
      "tf.Tensor(\n",
      "[[[ 0  1  2]\n",
      "  [ 3  4  5]]\n",
      "\n",
      " [[ 6  7  8]\n",
      "  [ 9 10 11]]], shape=(2, 2, 3), dtype=int32)\n",
      "\n",
      "Reshape with -1 (4x-1 becomes 4x3):\n",
      "tf.Tensor(\n",
      "[[ 0  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]], shape=(4, 3), dtype=int32)\n",
      "\n",
      "Flattened: tf.Tensor([ 0  1  2  3  4  5  6  7  8  9 10 11], shape=(12,), dtype=int32)\n",
      "\n",
      "Expanded dimensions (add batch): (1, 12)\n",
      "\n",
      "Original shape: (1, 1, 4)\n",
      "After squeeze: (4,)\n"
     ]
    }
   ],
   "source": [
    "# Reshaping tensors\n",
    "x = tf.range(12)\n",
    "print(\"Original 1D tensor:\", x)\n",
    "print(\"Shape:\", x.shape)\n",
    "\n",
    "# Reshape to 2D\n",
    "x_2d = tf.reshape(x, [3, 4])\n",
    "print(\"\\nReshaped to 3x4:\")\n",
    "print(x_2d)\n",
    "\n",
    "# Reshape to 3D\n",
    "x_3d = tf.reshape(x, [2, 2, 3])\n",
    "print(\"\\nReshaped to 2x2x3:\")\n",
    "print(x_3d)\n",
    "\n",
    "# Reshape with -1 (automatic dimension calculation)\n",
    "x_auto = tf.reshape(x, [4, -1])\n",
    "print(\"\\nReshape with -1 (4x-1 becomes 4x3):\")\n",
    "print(x_auto)\n",
    "\n",
    "# Flatten\n",
    "x_flat = tf.reshape(x_2d, [-1])\n",
    "print(\"\\nFlattened:\", x_flat)\n",
    "\n",
    "# Expand dimensions\n",
    "x_expanded = tf.expand_dims(x, axis=0)\n",
    "print(\"\\nExpanded dimensions (add batch):\", x_expanded.shape)\n",
    "\n",
    "# Squeeze (remove dimensions of size 1)\n",
    "x_squeezable = tf.constant([[[1, 2, 3, 4]]])\n",
    "print(\"\\nOriginal shape:\", x_squeezable.shape)\n",
    "print(\"After squeeze:\", tf.squeeze(x_squeezable).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f2ba53",
   "metadata": {},
   "source": [
    "### 9. Indexing and Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c59fb7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tf.Tensor(\n",
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]\n",
      " [15 16 17 18 19]], shape=(4, 5), dtype=int32)\n",
      "\n",
      "First row: tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int32)\n",
      "Element at [2, 3]: tf.Tensor(13, shape=(), dtype=int32)\n",
      "\n",
      "First 2 rows:\n",
      "tf.Tensor(\n",
      "[[0 1 2 3 4]\n",
      " [5 6 7 8 9]], shape=(2, 5), dtype=int32)\n",
      "\n",
      "Last 2 columns:\n",
      "tf.Tensor(\n",
      "[[ 3  4]\n",
      " [ 8  9]\n",
      " [13 14]\n",
      " [18 19]], shape=(4, 2), dtype=int32)\n",
      "\n",
      "Every other row:\n",
      "tf.Tensor(\n",
      "[[ 0  1  2  3  4]\n",
      " [10 11 12 13 14]], shape=(2, 5), dtype=int32)\n",
      "\n",
      "Rows 1 and 3:\n",
      "tf.Tensor(\n",
      "[[ 5  6  7  8  9]\n",
      " [15 16 17 18 19]], shape=(2, 5), dtype=int32)\n",
      "\n",
      "Mask (elements > 10):\n",
      "tf.Tensor(\n",
      "[[False False False False False]\n",
      " [False False False False False]\n",
      " [False  True  True  True  True]\n",
      " [ True  True  True  True  True]], shape=(4, 5), dtype=bool)\n",
      "Elements > 10: tf.Tensor([11 12 13 14 15 16 17 18 19], shape=(9,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Indexing and slicing\n",
    "tensor = tf.reshape(tf.range(20), [4, 5])\n",
    "print(\"Original tensor:\")\n",
    "print(tensor)\n",
    "\n",
    "# Basic indexing\n",
    "print(\"\\nFirst row:\", tensor[0])\n",
    "print(\"Element at [2, 3]:\", tensor[2, 3])\n",
    "\n",
    "# Slicing\n",
    "print(\"\\nFirst 2 rows:\")\n",
    "print(tensor[:2])\n",
    "print(\"\\nLast 2 columns:\")\n",
    "print(tensor[:, -2:])\n",
    "print(\"\\nEvery other row:\")\n",
    "print(tensor[::2])\n",
    "\n",
    "# Advanced indexing with gather\n",
    "print(\"\\nRows 1 and 3:\")\n",
    "print(tf.gather(tensor, [1, 3]))\n",
    "\n",
    "# Boolean indexing\n",
    "mask = tensor > 10\n",
    "print(\"\\nMask (elements > 10):\")\n",
    "print(mask)\n",
    "print(\"Elements > 10:\", tf.boolean_mask(tensor, mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc53db30",
   "metadata": {},
   "source": [
    "### 10. Aggregation Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08ac2d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tf.Tensor(\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]], shape=(3, 3), dtype=float32)\n",
      "\n",
      "Sum of all elements: tf.Tensor(45.0, shape=(), dtype=float32)\n",
      "Sum along axis 0 (columns): tf.Tensor([12. 15. 18.], shape=(3,), dtype=float32)\n",
      "Sum along axis 1 (rows): tf.Tensor([ 6. 15. 24.], shape=(3,), dtype=float32)\n",
      "\n",
      "Mean of all elements: tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "Mean along axis 0: tf.Tensor([4. 5. 6.], shape=(3,), dtype=float32)\n",
      "Mean along axis 1: tf.Tensor([2. 5. 8.], shape=(3,), dtype=float32)\n",
      "\n",
      "Max value: tf.Tensor(9.0, shape=(), dtype=float32)\n",
      "Min value: tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "Max along axis 0: tf.Tensor([7. 8. 9.], shape=(3,), dtype=float32)\n",
      "Argmax (index of max): tf.Tensor(8, shape=(), dtype=int64)\n",
      "\n",
      "Standard deviation: tf.Tensor(2.5819888, shape=(), dtype=float32)\n",
      "Variance: tf.Tensor(6.6666665, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Aggregation operations\n",
    "data = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]])\n",
    "print(\"Original tensor:\")\n",
    "print(data)\n",
    "\n",
    "# Sum\n",
    "print(\"\\nSum of all elements:\", tf.reduce_sum(data))\n",
    "print(\"Sum along axis 0 (columns):\", tf.reduce_sum(data, axis=0))\n",
    "print(\"Sum along axis 1 (rows):\", tf.reduce_sum(data, axis=1))\n",
    "\n",
    "# Mean\n",
    "print(\"\\nMean of all elements:\", tf.reduce_mean(data))\n",
    "print(\"Mean along axis 0:\", tf.reduce_mean(data, axis=0))\n",
    "print(\"Mean along axis 1:\", tf.reduce_mean(data, axis=1))\n",
    "\n",
    "# Max and Min\n",
    "print(\"\\nMax value:\", tf.reduce_max(data))\n",
    "print(\"Min value:\", tf.reduce_min(data))\n",
    "print(\"Max along axis 0:\", tf.reduce_max(data, axis=0))\n",
    "print(\"Argmax (index of max):\", tf.argmax(tf.reshape(data, [-1])))\n",
    "\n",
    "# Standard deviation and variance\n",
    "print(\"\\nStandard deviation:\", tf.math.reduce_std(data))\n",
    "print(\"Variance:\", tf.math.reduce_variance(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2c2067",
   "metadata": {},
   "source": [
    "### 11. Concatenation and Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33e03b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor 1:\n",
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n",
      "\n",
      "Tensor 2:\n",
      "tf.Tensor(\n",
      "[[5 6]\n",
      " [7 8]], shape=(2, 2), dtype=int32)\n",
      "\n",
      "Concatenate along axis 0 (vertical):\n",
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]\n",
      " [7 8]], shape=(4, 2), dtype=int32)\n",
      "\n",
      "Concatenate along axis 1 (horizontal):\n",
      "tf.Tensor(\n",
      "[[1 2 5 6]\n",
      " [3 4 7 8]], shape=(2, 4), dtype=int32)\n",
      "\n",
      "Stack along axis 0:\n",
      "tf.Tensor(\n",
      "[[[1 2]\n",
      "  [3 4]]\n",
      "\n",
      " [[5 6]\n",
      "  [7 8]]], shape=(2, 2, 2), dtype=int32)\n",
      "Shape: (2, 2, 2)\n",
      "\n",
      "Stack along axis 1:\n",
      "tf.Tensor(\n",
      "[[[1 2]\n",
      "  [5 6]]\n",
      "\n",
      " [[3 4]\n",
      "  [7 8]]], shape=(2, 2, 2), dtype=int32)\n",
      "Shape: (2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "# Concatenation and stacking\n",
    "t1 = tf.constant([[1, 2], [3, 4]])\n",
    "t2 = tf.constant([[5, 6], [7, 8]])\n",
    "\n",
    "print(\"Tensor 1:\")\n",
    "print(t1)\n",
    "print(\"\\nTensor 2:\")\n",
    "print(t2)\n",
    "\n",
    "# Concatenate\n",
    "print(\"\\nConcatenate along axis 0 (vertical):\")\n",
    "print(tf.concat([t1, t2], axis=0))\n",
    "\n",
    "print(\"\\nConcatenate along axis 1 (horizontal):\")\n",
    "print(tf.concat([t1, t2], axis=1))\n",
    "\n",
    "# Stack (creates new dimension)\n",
    "print(\"\\nStack along axis 0:\")\n",
    "stacked_0 = tf.stack([t1, t2], axis=0)\n",
    "print(stacked_0)\n",
    "print(\"Shape:\", stacked_0.shape)\n",
    "\n",
    "print(\"\\nStack along axis 1:\")\n",
    "stacked_1 = tf.stack([t1, t2], axis=1)\n",
    "print(stacked_1)\n",
    "print(\"Shape:\", stacked_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae988bd5",
   "metadata": {},
   "source": [
    "### 12. Summary: Rank and Shape across Different Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9ca9afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Tensor Type          Rank       Shape                     Total Elements \n",
      "======================================================================\n",
      "Scalar (0D)          0          ()                        1              \n",
      "Vector (1D)          1          (5,)                      5              \n",
      "Matrix (2D)          2          (3, 4)                    12             \n",
      "3D Tensor            3          (2, 3, 4)                 24             \n",
      "4D Tensor            4          (2, 3, 4, 5)              120            \n",
      "5D Tensor            5          (2, 3, 4, 5, 6)           720            \n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Summary of rank and shapes\n",
    "tensors_dict = {\n",
    "    \"Scalar (0D)\": tf.constant(42),\n",
    "    \"Vector (1D)\": tf.constant([1, 2, 3, 4, 5]),\n",
    "    \"Matrix (2D)\": tf.random.normal([3, 4]),\n",
    "    \"3D Tensor\": tf.random.normal([2, 3, 4]),\n",
    "    \"4D Tensor\": tf.random.normal([2, 3, 4, 5]),\n",
    "    \"5D Tensor\": tf.random.normal([2, 3, 4, 5, 6])\n",
    "}\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Tensor Type':<20} {'Rank':<10} {'Shape':<25} {'Total Elements':<15}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for name, tensor in tensors_dict.items():\n",
    "    rank = tf.rank(tensor).numpy()\n",
    "    shape = str(tuple(tensor.shape.as_list()))\n",
    "    numel = tf.size(tensor).numpy()\n",
    "    print(f\"{name:<20} {rank:<10} {shape:<25} {numel:<15}\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
